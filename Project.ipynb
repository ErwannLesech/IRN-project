{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a7a466-0710-425b-8991-d23dc09e4082",
   "metadata": {},
   "source": [
    "# TP 1\n",
    "## Groupe des amateurices de vin\n",
    "\n",
    "### Reconnaissance de vin.\n",
    "\n",
    "Dans ce projet, nous allons faire de la reconnaissance de vins.\n",
    "\n",
    "Source des données : https://huggingface.co/datasets/katossky/wine-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ba8e96-0d57-4481-9b28-c26530f1243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.io import read_image\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223a9b8a-aa0a-4d2d-8859-ba68b0de3915",
   "metadata": {},
   "source": [
    "### Étape 1 : Charger les données\n",
    "\n",
    "En PyTorch, les données doivent être transmise au réseau de neurones à l'aide d'un loader. La première étape est de créer une classe de type `Dataset` que la fonction `DataLoader` prend en argument. La classe doit au moins posséder les trois routine `__init__`, `__len__` et `__getitem__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed7918b-d6b4-4c12-a5f4-5ef129da89dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label  alcohol  malic acid   ash  alcalinity of ash  magnesium  \\\n",
      "0        1    14.23        1.71  2.43               15.6        127   \n",
      "1        1    13.20        1.78  2.14               11.2        100   \n",
      "2        1    13.16        2.36  2.67               18.6        101   \n",
      "3        1    14.37        1.95  2.50               16.8        113   \n",
      "4        1    13.24        2.59  2.87               21.0        118   \n",
      "..     ...      ...         ...   ...                ...        ...   \n",
      "173      3    13.71        5.65  2.45               20.5         95   \n",
      "174      3    13.40        3.91  2.48               23.0        102   \n",
      "175      3    13.27        4.28  2.26               20.0        120   \n",
      "176      3    13.17        2.59  2.37               20.0        120   \n",
      "177      3    14.13        4.10  2.74               24.5         96   \n",
      "\n",
      "     total phenols  flavanoids  nonflavanoid phenols  proanthocyanins  \\\n",
      "0             2.80        3.06                  0.28             2.29   \n",
      "1             2.65        2.76                  0.26             1.28   \n",
      "2             2.80        3.24                  0.30             2.81   \n",
      "3             3.85        3.49                  0.24             2.18   \n",
      "4             2.80        2.69                  0.39             1.82   \n",
      "..             ...         ...                   ...              ...   \n",
      "173           1.68        0.61                  0.52             1.06   \n",
      "174           1.80        0.75                  0.43             1.41   \n",
      "175           1.59        0.69                  0.43             1.35   \n",
      "176           1.65        0.68                  0.53             1.46   \n",
      "177           2.05        0.76                  0.56             1.35   \n",
      "\n",
      "     color intensity   hue  OD280/OD315 of diluted wines  proline  \n",
      "0               5.64  1.04                          3.92     1065  \n",
      "1               4.38  1.05                          3.40     1050  \n",
      "2               5.68  1.03                          3.17     1185  \n",
      "3               7.80  0.86                          3.45     1480  \n",
      "4               4.32  1.04                          2.93      735  \n",
      "..               ...   ...                           ...      ...  \n",
      "173             7.70  0.64                          1.74      740  \n",
      "174             7.30  0.70                          1.56      750  \n",
      "175            10.20  0.59                          1.56      835  \n",
      "176             9.30  0.60                          1.62      840  \n",
      "177             9.20  0.61                          1.60      560  \n",
      "\n",
      "[178 rows x 14 columns]\n",
      "[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      " 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]\n",
      "Sample features: tensor([ 1.5186, -0.5622,  0.2321, -1.1696,  1.9139,  0.8090,  1.0348, -0.6596,\n",
      "         1.2249,  0.2517,  0.3622,  1.8479,  1.0130])\n",
      "Sample label: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wineDataset = pd.read_csv(\"wine-dataset/wine.csv\")\n",
    "\n",
    "print(wineDataset)\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "        \n",
    "        self.labels = self.data.iloc[:, 0].values  # first column is label\n",
    "        self.features = self.data.iloc[:, 1:].values  # All other columns are features\n",
    "        \n",
    "        # Normalize the features (if needed)\n",
    "        self.features = (self.features - self.features.mean(axis=0)) / self.features.std(axis=0)\n",
    "        \n",
    "        # Ensure labels are binary (0 and 1)\n",
    "        label_min = self.labels.min()\n",
    "        label_max = self.labels.max()\n",
    "        if label_max - label_min != 0:\n",
    "            self.labels = (self.labels - label_min) / (label_max - label_min)\n",
    "        else:\n",
    "            self.labels = self.labels * 0\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32).unsqueeze(0)  # or torch.float32 if needed\n",
    "        return features, label\n",
    "\n",
    "# Instantiate the dataset\n",
    "wine_dataset = WineDataset(wineDataset)\n",
    "\n",
    "# Print the labels to verify\n",
    "print(wine_dataset.labels)\n",
    "\n",
    "# Example: Fetch a sample to verify\n",
    "features, label = wine_dataset[0]\n",
    "print(f'Sample features: {features}')\n",
    "print(f'Sample label: {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e70aed5-b312-4f3a-be3d-18d0913c3377",
   "metadata": {},
   "source": [
    "### Etape 2 : Construire le model du réseau de neurones\n",
    "\n",
    "Dans cette partie, nous élaborons notre model afin qu'il puisse être entrainé sur notre dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57679e46-57fe-4083-a4bf-146589b7f333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=13, out_features=1, bias=True)\n",
      "  (1): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "wineModel = torch.nn.Sequential(torch.nn.Linear(13,1),\n",
    "                                torch.nn.Sigmoid())\n",
    "print(wineModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9542f5-70d9-4cc7-af70-821ce8c2b239",
   "metadata": {},
   "source": [
    "### Etape 3 : Choisir une fonction coût"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc3772a-09ec-4085-96aa-8b0635e15fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(wineModel.parameters(), lr = 0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae99fb53-415d-4583-923e-9f855b8525e3",
   "metadata": {},
   "source": [
    "### Étape 4 : création des loader d'entraintement, de validation et de test\n",
    "\n",
    "Ici on choisit un batch de 20.\n",
    "\n",
    "Pour une taille de batch de 20, on coupera le jeu de donnée de la manière suivante : \n",
    "- Entrainement de la partie 1 à la partie 120,\n",
    "- Validation de la partie 120 à la partie 160,\n",
    "- Test de la partie 160 à la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5505f134-531e-433a-8c8f-15654a75f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for train, validation, and test datasets\n",
    "train_path = wineDataset.iloc[:120]\n",
    "val_path = wineDataset.iloc[120:160]\n",
    "test_path = wineDataset.iloc[160:]\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = WineDataset(train_path)\n",
    "val_dataset = WineDataset(val_path)\n",
    "test_dataset = WineDataset(test_path)\n",
    "\n",
    "# Define batch size\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a92d1-d1a1-4336-9c64-d81e5fa39b78",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ce7a62e-7069-4be5-a99b-e28e0a5496d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Print_loss_accuracy(nepoch, tloss, vloss, accuracy, best_tloss, best_vloss, best_accuracy):\n",
    "    print (\"{:<6} {:<15} {:<17} {:<15} {:<20} {:<22} {:<15}\".format(nepoch, tloss, vloss, accuracy, best_tloss, best_vloss, best_accuracy))\n",
    "\n",
    "def learning(nepoch, model, crit, optim, batchsize, trainingloader, validationloader):\n",
    "    best_tloss = 100.\n",
    "    best_vloss = 100.\n",
    "    best_accuracy = 0.\n",
    "    Print_loss_accuracy('Epoch', 'training loss', 'validation loss', 'accuracy', 'best train loss', 'best validation loss', 'best accuracy')\n",
    "    \n",
    "    for epoch in range(nepoch):\n",
    "        tloss = 0.\n",
    "        vloss = 0.\n",
    "        correct_test = 0\n",
    "        model.train()\n",
    "        \n",
    "        for features, labels in trainingloader:\n",
    "            optim.zero_grad()\n",
    "            predicted = model(features).squeeze(dim=1)\n",
    "            loss = crit(predicted, labels)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            tloss += loss.item() * features.size(0)\n",
    "        \n",
    "        tloss /= len(trainingloader.sampler)\n",
    "        model.eval()\n",
    "        \n",
    "        for features, labels in validationloader:\n",
    "            predicted = model(features).squeeze(dim=1)\n",
    "            loss = crit(predicted, labels.squeeze(dim=1))\n",
    "            correct_test += np.sum(predicted.round().detach().numpy() == labels.squeeze().detach().numpy())\n",
    "            vloss += loss.item() * features.size(0)\n",
    "        \n",
    "        vloss /= len(validationloader.sampler)\n",
    "        accuracy = 100 * correct_test / len(validationloader.dataset)\n",
    "\n",
    "        if accuracy >= best_accuracy:\n",
    "            torch.save(model, \"best_model.pth\")\n",
    "            best_accuracy = accuracy\n",
    "        if vloss <= best_vloss:\n",
    "            best_vloss = vloss\n",
    "        if tloss <= best_tloss:\n",
    "            best_tloss = tloss\n",
    "        \n",
    "        print_loss_accuracy(epoch + 1, \n",
    "                            np.round(tloss, 8), \n",
    "                            np.round(vloss, 8), \n",
    "                            np.round(accuracy, 8), \n",
    "                            np.round(best_tloss, 8), \n",
    "                            np.round(best_vloss, 8), \n",
    "                            np.round(best_accuracy, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd89aca5-1e8f-4181-985b-3fc52cf7afb6",
   "metadata": {},
   "source": [
    "### Test model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed3c5c99-d923-4fee-bd1f-55c268de71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Testmodel(modelfile, crit, testloader):\n",
    "    # Load the trained model\n",
    "    model = torch.load(modelfile)\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    plt.figure(dpi=300)\n",
    "    ct = 1\n",
    "    for features, labels in testloader:\n",
    "        image = features[0].permute(1, 2, 0)\n",
    "        plt.subplot(1, len(test_loader.sampler), ct)\n",
    "        plt.imshow(image)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        predicted = model(features).squeeze(dim=1)\n",
    "        loss = crit(predicted, labels.squeeze(dim=1))\n",
    "        plt.title('True label : {} \\n Predicted label : {} \\n Test loss : {}'.format(labels.squeeze().detach().numpy(), \n",
    "                                                                       predicted.round().detach().numpy(),\n",
    "                                                                       np.round(test_loss.item(), 2)),\n",
    "                  fontsize=6)\n",
    "        ct += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65919506-ceec-4f9b-b0d8-947fa8fbbc54",
   "metadata": {},
   "source": [
    "### Training & Test\n",
    "\n",
    "C'est le moment de s'amuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0be17d25-af7e-4ffe-a4f9-e8d717426070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  training loss   validation loss   accuracy        best train loss      best validation loss   best accuracy  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([20, 1])) that is different to the input size (torch.Size([20])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlearning\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwineModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(val_loader\u001b[38;5;241m.\u001b[39mdataset))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#Testmodel(\"best_model.pth\", criterion, test_loader)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m, in \u001b[0;36mlearning\u001b[0;34m(nepoch, model, crit, optim, batchsize, trainingloader, validationloader)\u001b[0m\n\u001b[1;32m     17\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m predicted \u001b[38;5;241m=\u001b[39m model(features)\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcrit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     21\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/functional.py:3145\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3143\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3148\u001b[0m     )\n\u001b[1;32m   3150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3151\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([20, 1])) that is different to the input size (torch.Size([20])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "learning(50, wineModel, criterion, optimizer, BATCH_SIZE, train_loader, val_loader)\n",
    "\n",
    "print(len(val_loader.dataset))\n",
    "\n",
    "#Testmodel(\"best_model.pth\", criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d92b98-2115-4f78-a12c-d97be696e5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
